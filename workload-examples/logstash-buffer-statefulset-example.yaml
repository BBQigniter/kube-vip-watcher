# for creating the namespace if it's missing
apiVersion: v1
kind: Namespace
metadata:
  name: logstash-buffer
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: logstash-buffer
  namespace: logstash-buffer
  labels:
    app: logstash-buffer
spec:
  replicas: 3
  selector:
    matchLabels:
      app: logstash-buffer
  serviceName: "logstash-buffer"
  podManagementPolicy: "Parallel"
  template:
    metadata:
      annotations:
        co.elastic.logs/module: logstash
        kubeVipBalanceIP: "true"
      labels:
        app: logstash-buffer
        stackmonitoring: logstash
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
      - image: docker.elastic.co/logstash/logstash:7.17.3
        name: logstash-buffer
        ports:
        - containerPort: 9600
          name: https
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 90
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 90
          periodSeconds: 5
        env:
        - name: LS_JAVA_OPTS
          value: "-Xms1g -Xmx1g"
        # we have to check what are good resource levels
        resources:
          requests:
            memory: 512Mi
            cpu: 1
          limits:
            memory: 2Gi
            # so it cannot take all CPUs if something is wrong with Logstash
            cpu: 2
        volumeMounts:
        - name: config-volume
          mountPath: /usr/share/logstash/config/logstash.yml
          subPath: logstash.yml
          readOnly: true
        - name: config-volume
          mountPath: /usr/share/logstash/pipeline/logstash.conf
          subPath: logstash.conf
          readOnly: true
        - name: log-data
          mountPath: /data
      volumes:
      - name: config-volume
        configMap:
          name: logstash-buffer-configmap
  # to reclaim an existing persistent volume - check first it's state: kubectl get pv
  # it should either not exist yet or if you want to reclaim it you have to remove it's claimref-uid
  # e.g. kubectl patch persistentvolume/pv006 --type json -p '[{"op": "remove", "path": "/spec/claimRef/uid"}]'
  volumeClaimTemplates:
  - metadata:
      name: log-data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 5Gi
      storageClassName: local-storage
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-buffer-configmap
  namespace: logstash-buffer
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    http.port: 9600
    monitoring.enabled: false
    xpack.management.enabled: false
    log.format: json
  logstash.conf: |
   input {
     tcp {
       port => 12345
       dns_reverse_lookup_enabled => false
       ecs_compatibility => "disabled"
       tags => ["tcp"]
     }
     
     udp {
       port => 12345
       ecs_compatibility => "disabled"
       tags => ["udp"]
     }
   }
   
   output {
     stdout {
       #codec => "json"
     }
   }
---
apiVersion: v1
kind: Service
metadata:
  name: logstash-buffer-0
  namespace: logstash-buffer
  labels:
    app: logstash-buffer
  annotations:
    kubeVipBalancePriority: "vkube-4, vkube-5, vkube-6"
spec:
  ports:
  - port: 514
    targetPort: 12345
    protocol: TCP
    name: syslog-tcp
  - port: 514
    targetPort: 12345
    protocol: UDP
    name: syslog-udp
  selector:
    app: logstash-buffer
  sessionAffinity: None
  type: LoadBalancer
  externalTrafficPolicy: Local
  loadBalancerIP: "10.115.199.122"
---
apiVersion: v1
kind: Service
metadata:
  name: logstash-buffer-1
  namespace: logstash-buffer
  labels:
    app: logstash-buffer
  annotations:
    kubeVipBalancePriority: "vkube-5, vkube-6, vkube-4"
spec:
  ports:
  - port: 514
    targetPort: 12345
    protocol: TCP
    name: syslog-tcp
  - port: 514
    targetPort: 12345
    protocol: UDP
    name: syslog-udp
  selector:
    app: logstash-buffer
  sessionAffinity: None
  type: LoadBalancer
  externalTrafficPolicy: Local
  loadBalancerIP: "10.115.199.123"
---
apiVersion: v1
kind: Service
metadata:
  name: logstash-buffer-2
  namespace: logstash-buffer
  labels:
    app: logstash-buffer
  annotations:
    kubeVipBalancePriority: "vkube-6, vkube-4, vkube-5"
spec:
  ports:
  - port: 514
    targetPort: 12345
    protocol: TCP
    name: syslog-tcp
  - port: 514
    targetPort: 12345
    protocol: UDP
    name: syslog-udp
  selector:
    app: logstash-buffer
  sessionAffinity: None
  type: LoadBalancer
  externalTrafficPolicy: Local
  loadBalancerIP: "10.115.199.124"
---
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-001-logstash-buffer-0
spec:
  # has no effect but needed
  capacity:
    storage: 5Gi
  accessModes:
  - ReadWriteOnce
  # Delete is not working in this case!
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    # the folder has to be created before applying this yaml
    path: /data/pv-001-logstash-buffer-0
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - vkube-4
  claimRef:
    # the pattern is: log-data-PODNAME-PODNUMBER
    name: log-data-logstash-buffer-0
    namespace: logstash-buffer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-002-logstash-buffer-1
spec:
  # has no effect but needed
  capacity:
    storage: 5Gi
  accessModes:
  - ReadWriteOnce
  # Delete is not working in this case!
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    # the folder has to be created before applying this yaml
    path: /data/pv-002-logstash-buffer-1
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - vkube-5
  claimRef:
    # the pattern is: log-data-PODNAME-PODNUMBER
    name: log-data-logstash-buffer-1
    namespace: logstash-buffer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-003-logstash-buffer-2
spec:
  # has no effect but needed
  capacity:
    storage: 5Gi
  accessModes:
  - ReadWriteOnce
  # Delete is not working in this case!
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  local:
    # the folder has to be created before applying this yaml
    path: /data/pv-003-logstash-buffer-2
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - vkube-6
  claimRef:
    # the pattern is: log-data-PODNAME-PODNUMBER
    name: log-data-logstash-buffer-2
    namespace: logstash-buffer